Absolutely! Below is a **Replit-ready FastAPI app prompt** that meets **all HackRx webhook requirements**, including:

* ✅ **HTTPS** (Replit provides it automatically)
* ✅ `/hackrx/run` route
* ✅ `Authorization: Bearer ...` header check
* ✅ JSON input: `documents` + `questions`
* ✅ Parses `.pdf` from URL
* ✅ Returns: `{"answers": ["..."]}` (only strings, not JSON inside)
* ✅ Integrates Gemini + Pinecone

---

## ✅ Prompt for Replit (Complete)

Use this prompt to create a working backend on Replit:

---

**Prompt to Replit:**

> Create a FastAPI app with the following features:
>
> 1. **POST /hackrx/run** route.
>
> 2. Requires `Authorization: Bearer 9953d967b81381295864fb71b20cd27085ee80c24512eeabce64f3f921bb009d` header.
>
> 3. Accepts JSON body with:
>
>    * `documents`: URL to a `.pdf` or `.docx` file
>    * `questions`: list of strings
>
> 4. Downloads the document and parses text (for `.pdf`, use PyMuPDF).
>
> 5. Splits text into overlapping chunks (500 words, 100 word overlap).
>
> 6. For each chunk:
>
>    * Generate embeddings using Gemini's `embedding-001` model
>    * Upsert into Pinecone with metadata `{"text": chunk}`
>
> 7. For each question:
>
>    * Embed using Gemini `embedding-001`
>    * Search Pinecone top 5 chunks
>    * Pass question + matched chunks into Gemini `gemini-pro` with this prompt:
>
>    ```
>    You are a legal AI. Based on the following text chunks, answer this question:
>    "{question}"
>
>    Chunks:
>    - {chunk1}
>    - {chunk2}
>    ...
>
>    Return a JSON with keys: answer, condition, rationale.
>    ```
>
>    * Extract only the `answer` field from the JSON response.
>
> 8. Return response as:
>
>    ```json
>    {
>      "answers": [
>        "string answer 1",
>        "string answer 2",
>        ...
>      ]
>    }
>    ```
>
> 9. Add `.replit`:
>
>    ```
>    run = "uvicorn main:app --host=0.0.0.0 --port=8000"
>    ```
>
> 10. Include `requirements.txt`:
>
>     ```
>     fastapi
>     uvicorn
>     pydantic
>     requests
>     PyMuPDF
>     python-docx
>     google-generativeai
>     pinecone-client
>     ```
>
> 11. Use environment variables:
>
>     * `GEMINI_API_KEY`
>     * `PINECONE_API_KEY`
>     * `PINECONE_INDEX`
>     * `PINECONE_ENV` (e.g., "us-west-2")
>
> ✅ Test the endpoint with Postman using the given bearer token and document+question payload.

---

### ✅ Bonus: If you’re using Replit’s **"AI" or "ghostwriter"**, paste this whole prompt — it will scaffold the project for you.

Let me know if you want the **actual `main.py`, `gemini_utils.py`, `search.py`, `chunker.py`**, and others as a full starter template ready to copy–paste into Replit.
